{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b9fd0c",
   "metadata": {},
   "source": [
    "### Sentiment analysis and Text Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a3e09b",
   "metadata": {},
   "source": [
    "Objective : To build and train a model that can predict if a sentence has positive or negative sentiments.\n",
    "\n",
    "For example:\n",
    "1. \"This is teribble and I am disappointed\"\n",
    "- should be predicted as negative.\n",
    "\n",
    "2. \"I am quite happy with this\"\n",
    "- should be predicted as positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4854a5a6",
   "metadata": {},
   "source": [
    "#### Overview: Steps to classification\n",
    "\n",
    "1. Getting a dataset with labelled sentiments\n",
    "2. Installing relevent libraries\n",
    "3. Reading dataset using pandas\n",
    "4. Separating X (predictor) and Y (target) variables.\n",
    "5. Converting test to vectorsusing Sklearn TdifVector\n",
    "6. Building and Training our classification model\n",
    "7. Evaluating our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32822c87",
   "metadata": {},
   "source": [
    "#### The dataset\n",
    "- 0 means a negative sentiment\n",
    "- 1 means a positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6aa8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"sentiment_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e47e01e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Think Dallas - the dream: I think this author...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Great Condition: I ordered this book as gift ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>smells great: purchased this for my father fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Horrible horrible horrible CAT REACTION!!!: T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>DOG TRAINING FOR SADISTS: We bought this book...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Praise for Lewis!: C.S. Lewis's On Stories is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Difficult to read.. but well written.: This b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>More basic than earlier seasons, but in some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>a disappointed fan: I guess my problem is I k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Sophisticatedly stupid: Ok, first of all, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent!: This is certainly an excellent CD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Much too firm.: I had high expectations for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>what sequels are made of: Many people for get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>Interesting thesis but ultimately incorrect: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>It is not a textbook: Like all Timoshenko's b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>Works: This was a convenient way to cart my s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>Pure Genius: When i first listened to this al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>Sweet Gloves: I bought an 80 lb everlast heav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>Even mediocre Roddenberry is good fun: Very g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>Barely worth reading, if at all!: I thought t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                             review\n",
       "0           0   Think Dallas - the dream: I think this author...\n",
       "1           1   Great Condition: I ordered this book as gift ...\n",
       "2           1   smells great: purchased this for my father fo...\n",
       "3           0   Horrible horrible horrible CAT REACTION!!!: T...\n",
       "4           0   DOG TRAINING FOR SADISTS: We bought this book...\n",
       "5           1   Praise for Lewis!: C.S. Lewis's On Stories is...\n",
       "6           1   Difficult to read.. but well written.: This b...\n",
       "7           1   More basic than earlier seasons, but in some ...\n",
       "8           0   a disappointed fan: I guess my problem is I k...\n",
       "9           0   Sophisticatedly stupid: Ok, first of all, thi...\n",
       "10          1   Excellent!: This is certainly an excellent CD...\n",
       "11          0   Much too firm.: I had high expectations for t...\n",
       "12          1   what sequels are made of: Many people for get...\n",
       "13          0   Interesting thesis but ultimately incorrect: ...\n",
       "14          0   It is not a textbook: Like all Timoshenko's b...\n",
       "15          1   Works: This was a convenient way to cart my s...\n",
       "16          1   Pure Genius: When i first listened to this al...\n",
       "17          1   Sweet Gloves: I bought an 80 lb everlast heav...\n",
       "18          1   Even mediocre Roddenberry is good fun: Very g...\n",
       "19          0   Barely worth reading, if at all!: I thought t..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4cddce",
   "metadata": {},
   "source": [
    "#### Separating X (predictor) and Y (target) variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2043c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"sentiment\"]\n",
    "xraw = data[\"review\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ea9c65",
   "metadata": {},
   "source": [
    "####  Converting text to vector using SKlearn TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3cfd7ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit_transform() missing 1 required positional argument: 'raw_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dx/tzmn0d1j2cn3c33_rdvb0jxw0000gn/T/ipykernel_19836/2401905049.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit_transform() missing 1 required positional argument: 'raw_documents'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "vec = TfidfVectorizer \n",
    "x = vec.fit_transform(xraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b56eea27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dx/tzmn0d1j2cn3c33_rdvb0jxw0000gn/T/ipykernel_19836/1441669852.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x = x.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699682e",
   "metadata": {},
   "source": [
    "####  Building & training our classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "520b0a51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dx/tzmn0d1j2cn3c33_rdvb0jxw0000gn/T/ipykernel_19836/2377334439.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd153d86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dx/tzmn0d1j2cn3c33_rdvb0jxw0000gn/T/ipykernel_19836/1197411868.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd90835",
   "metadata": {},
   "source": [
    "#### Evaluating our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e040b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score(x_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01238124",
   "metadata": {},
   "outputs": [],
   "source": [
    "test =[\n",
    "    \"This is terrible and I am disappointed\",\n",
    "    \"I am quite happy with this\",\n",
    "    \"Never going to buy from this store ever again\",\n",
    "    \"Works pretty well and functions as it should\"\n",
    "]\n",
    "\n",
    "x_test = vec.transform(test)\n",
    "predictions = model.predict(x_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3491532",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
